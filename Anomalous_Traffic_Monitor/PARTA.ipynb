{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PARTA.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQoq-VNfYdIV"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndi1zy1iajOj"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive\")\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfea1KwFEYhy"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#  导入数据\n",
        "TRAIN_SPLIT = 30000\n",
        "\n",
        "# 导入网络访问数据\n",
        "# 通过分析网络流量来学习正常和异常行为，尝试将神经网络模型应用到入侵检测中，来解决高误报率的问题\n",
        "# 数据集选择CICIDS2017，这是加拿大网络安全研究所于2017年发布的数据集\n",
        "# 使用Pandas对CICIDS2017数据集进行数据预处理，清洗数据集并标准化\n",
        "import datetime\n",
        "\n",
        "start_time = datetime.datetime.now()\n",
        "CSV_FILE_PATH = 'binary_classification.csv'\n",
        "df = pd.read_csv(CSV_FILE_PATH)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5jtM7mBL4JH"
      },
      "source": [
        "#修改数据类型\n",
        "#Object类型转换为离散数值（Label列）\n",
        "df['Label'] = pd.Categorical(df['Label'])\n",
        "df['Label'] = df['Label'].cat.codes\n",
        "columns_counts = df.shape[1]                                                     #获取列数\n",
        "for i in range(columns_counts): # 把不是float 类型的数据转化为float\n",
        "  if(df.iloc[:,i].dtypes) != 'float64':\n",
        "    df.iloc[:, i] = df.iloc[:,i].astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO-KRBdQL6-b"
      },
      "source": [
        "#选取11个特征和Label\n",
        "features_considered = ['Bwd_Packet_Length_Min','Subflow_Fwd_Bytes','Total_Length_of_Fwd_Packets','Fwd_Packet_Length_Mean','Bwd_Packet_Length_Std','Flow_Duration','Flow_IAT_Std','Init_Win_bytes_forward','Bwd_Packets/s',\n",
        "                 'PSH_Flag_Count','Average_Packet_Size']\n",
        "features = df[features_considered]\n",
        "data_result = df['Target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U2r8RXUL8X8"
      },
      "source": [
        "# 对数据进行聚类\n",
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=5) # 聚类5      \n",
        "kmeans.fit(features) # 训练模型\n",
        "label = kmeans.predict(features) # 预测模型"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-N_X8IYL_vM"
      },
      "source": [
        "# 添加聚类结果\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "features['lb']=label\n",
        "features_considered.append(\"lb\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKc8S_dqMKIF"
      },
      "source": [
        "#标准化\n",
        "dataset = features.values\n",
        "feature_mean = dataset.mean(axis=0)\n",
        "feature_std = dataset.std(axis=0)\n",
        "dataset = (dataset-feature_mean)/feature_std\n",
        "dataset = pd.DataFrame(dataset,columns=features_considered)\n",
        "dataset.insert(0,'Target',data_result)\n",
        "dataset = dataset.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHIyfCcdMTGW"
      },
      "source": [
        "#返回时间窗,根据给定步长对过去的观察进行采样  history_size为过去信息窗口的大小，target_size为模型需要预测的未来时间\n",
        "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
        "                      target_size, step, single_step=False):\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  start_index = start_index + history_size\n",
        "  if end_index is None:\n",
        "    end_index = len(dataset) - target_size                                      #如果未指定end_index,则设置最后一个训练点\n",
        "\n",
        "  for i in range(start_index, end_index):\n",
        "    indices = range(i-history_size, i, step)\n",
        "    data.append(dataset[indices])\n",
        "\n",
        "    if single_step:\n",
        "      labels.append(target[i+target_size])                                      #仅仅预测未来的单个点\n",
        "    else:\n",
        "      labels.append(target[i:i+target_size])\n",
        "\n",
        "  return np.array(data), np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ebosaA0MUiO"
      },
      "source": [
        "past_history = 10000\n",
        "future_target = 100\n",
        "STEP = 6 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57JNaG8QMXDc"
      },
      "source": [
        "x_train_single, y_train_single = multivariate_data(dataset, dataset[:, 0], 0,\n",
        "                                                   TRAIN_SPLIT, past_history,\n",
        "                                                   future_target, STEP,\n",
        "                                                   single_step=True)            #dataset[:,1]取最后一列的所有值\n",
        "x_val_single, y_val_single = multivariate_data(dataset, dataset[:, 0],\n",
        "                                               TRAIN_SPLIT, None, past_history,\n",
        "                                               future_target, STEP,\n",
        "                                               single_step=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6aOY2lIMbOc"
      },
      "source": [
        "#训练集、验证集\n",
        "BATCH_SIZE = 256\n",
        "BUFFER_SIZE = 10000\n",
        "# 构建lstm 的数据\n",
        "train_data_single = tf.data.Dataset.from_tensor_slices((x_train_single, y_train_single))\n",
        "train_data_single = train_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "\n",
        "val_data_single = tf.data.Dataset.from_tensor_slices((x_val_single, y_val_single))\n",
        "val_data_single = val_data_single.batch(BATCH_SIZE).repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3fd0b7JMgYW"
      },
      "source": [
        "#创建模型\n",
        "model = tf.keras.Sequential([\n",
        "    layers.LSTM(32,\n",
        "                input_shape=x_train_single.shape[-2:]),\n",
        "    layers.Dense(32),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nYYwQ4DMj6s"
      },
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics=['accuracy']) # 设置优化器\n",
        "\n",
        "log_dir = \"graph/log_fit/7\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)# 打印log\n",
        "\n",
        "model.fit(x_train_single, y_train_single, epochs=10, batch_size=256,callbacks=[tensorboard_callback]) # 训练模型\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BANYvSJohfqo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4jOAUNva6Rm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}